<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Bruno Loureiro </title> <meta name="author" content="Bruno Loureiro"> <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar."> <meta name="keywords" content="Machine Learning, Statistical Physics, high-dimensional Statistics"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%94%8D&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://brloureiro.github.io/publications/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?bf50d6d9dd867d3e0f3b0add94449649"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Bruno Loureiro </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/bio/">bio </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/group/">group </a> </li> <li class="nav-item "> <a class="nav-link" href="/jobs/">jobs </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p> </header> <article> <div class="publications"> <h2 class="bibliography">2026</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="mattei2026welltemperedclassifierelementaryproperties" class="col-sm-8"> <div class="title">The Well-Tempered Classifier: Some Elementary Properties of Temperature Scaling</div> <div class="author"> Pierre-Alexandre Mattei ,  and  Bruno Loureiro </div> <div class="periodical"> 2026 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">mattei2026welltemperedclassifierelementaryproperties</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Well-Tempered Classifier: Some Elementary Properties of Temperature Scaling}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mattei, Pierre-Alexandre and Loureiro, Bruno}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2026}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2602.14862}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{stat.ML}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2602.14862}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="fogliani2026annealingvariationalinferencemitigates" class="col-sm-8"> <div class="title">Annealing in variational inference mitigates mode collapse: A theoretical study on Gaussian mixtures</div> <div class="author"> Luigi Fogliani ,  Bruno Loureiro ,  and  Marylou Gabrié </div> <div class="periodical"> 2026 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">fogliani2026annealingvariationalinferencemitigates</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Annealing in variational inference mitigates mode collapse: A theoretical study on Gaussian mixtures}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fogliani, Luigi and Loureiro, Bruno and Gabrié, Marylou}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2026}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2602.12923}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{stat.ML}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2602.12923}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="defilippis2026optimalscalinglawslearning" class="col-sm-8"> <div class="title">Optimal scaling laws in learning hierarchical multi-index models</div> <div class="author"> Leonardo Defilippis ,  Florent Krzakala ,  Bruno Loureiro , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Antoine Maillard' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> 2026 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">defilippis2026optimalscalinglawslearning</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Optimal scaling laws in learning hierarchical multi-index models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Defilippis, Leonardo and Krzakala, Florent and Loureiro, Bruno and Maillard, Antoine}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2026}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2602.05846}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{stat.ML}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2602.05846}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="nwemadji2026pretraininghurtslorafinetuning" class="col-sm-8"> <div class="title">When pre-training hurts LoRA fine-tuning: a dynamical analysis via single-index models</div> <div class="author"> Gibbs Nwemadji ,  Bruno Loureiro ,  and  Jean Barbier </div> <div class="periodical"> 2026 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">nwemadji2026pretraininghurtslorafinetuning</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{When pre-training hurts LoRA fine-tuning: a dynamical analysis via single-index models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nwemadji, Gibbs and Loureiro, Bruno and Barbier, Jean}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2026}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2602.02855}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.LG}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2602.02855}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="zurich2026randommatrixtheorymasked" class="col-sm-8"> <div class="title">A Random Matrix Theory of Masked Self-Supervised Regression</div> <div class="author"> Arie Wortsman Zurich ,  Federica Gerace ,  Bruno Loureiro , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Yue M. Lu' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> 2026 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">zurich2026randommatrixtheorymasked</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Random Matrix Theory of Masked Self-Supervised Regression}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zurich, Arie Wortsman and Gerace, Federica and Loureiro, Bruno and Lu, Yue M.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2026}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2601.23208}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{stat.ML}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2601.23208}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="braun2025fastescapeslowconvergence" class="col-sm-8"> <div class="title">Fast Escape, Slow Convergence: Learning Dynamics of Phase Retrieval under Power-Law Data</div> <div class="author"> Guillaume Braun ,  Bruno Loureiro ,  Ha Quang Minh , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Masaaki Imaizumi' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">braun2025fastescapeslowconvergence</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fast Escape, Slow Convergence: Learning Dynamics of Phase Retrieval under Power-Law Data}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Braun, Guillaume and Loureiro, Bruno and Minh, Ha Quang and Imaizumi, Masaaki}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2511.18661}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{stat.ML}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2511.18661}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="han2025opticalkernelmachineprogrammable" class="col-sm-8"> <div class="title">Optical kernel machine with programmable nonlinearity</div> <div class="author"> SeungYun Han ,  Fei Xia ,  Sylvain Gigan , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Bruno Loureiro, Hui Cao' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">han2025opticalkernelmachineprogrammable</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Optical kernel machine with programmable nonlinearity}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Han, SeungYun and Xia, Fei and Gigan, Sylvain and Loureiro, Bruno and Cao, Hui}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2511.17880}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{physics.optics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2511.17880}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="wortsman2025kernelridge" class="col-sm-8"> <div class="title">Kernel ridge regression under power-law data: spectrum and generalization</div> <div class="author"> Arie Wortsman ,  and  Bruno Loureiro </div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">wortsman2025kernelridge</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Kernel ridge regression under power-law data: spectrum and generalization}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wortsman, Arie and Loureiro, Bruno}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2510.04780}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{stat.ML}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2510.04780}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="defilippis2025scalinglawsspectrashallow" class="col-sm-8"> <div class="title">Scaling Laws and Spectra of Shallow Neural Networks in the Feature Learning Regime</div> <div class="author"> Leonardo Defilippis ,  Yizhou Xu ,  Julius Girardin , and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Emanuele Troiani, Vittorio Erba, Lenka Zdeborová, Bruno Loureiro, Florent Krzakala' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">defilippis2025scalinglawsspectrashallow</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Scaling Laws and Spectra of Shallow Neural Networks in the Feature Learning Regime}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Defilippis, Leonardo and Xu, Yizhou and Girardin, Julius and Troiani, Emanuele and Erba, Vittorio and Zdeborová, Lenka and Loureiro, Bruno and Krzakala, Florent}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2509.24882}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.LG}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2509.24882}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="duranthon2025statisticaladvantagesoftmaxattention" class="col-sm-8"> <div class="title">Statistical Advantage of Softmax Attention: Insights from Single-Location Regression</div> <div class="author"> O. Duranthon ,  P. Marion ,  C. Boyer , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'B. Loureiro, L. Zdeborová' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">duranthon2025statisticaladvantagesoftmaxattention</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Statistical Advantage of Softmax Attention: Insights from Single-Location Regression}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Duranthon, O. and Marion, P. and Boyer, C. and Loureiro, B. and Zdeborová, L.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2509.21936}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.LG}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2509.21936}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="ayme2025breakingcursedimensionalitylinear" class="col-sm-8"> <div class="title">Breaking the curse of dimensionality for linear rules: optimal predictors over the ellipsoid</div> <div class="author"> Alexis Ayme ,  and  Bruno Loureiro </div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">ayme2025breakingcursedimensionalitylinear</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Breaking the curse of dimensionality for linear rules: optimal predictors over the ellipsoid}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ayme, Alexis and Loureiro, Bruno}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2509.21174}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{stat.ML}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2509.21174}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="vilucchio2025existenceconsistentadversarialattacks" class="col-sm-8"> <div class="title">On the existence of consistent adversarial attacks in high-dimensional linear classification</div> <div class="author"> Matteo Vilucchio ,  Lenka Zdeborová ,  and  Bruno Loureiro </div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">vilucchio2025existenceconsistentadversarialattacks</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On the existence of consistent adversarial attacks in high-dimensional linear classification}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Vilucchio, Matteo and Zdeborová, Lenka and Loureiro, Bruno}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2506.12454}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{stat.ML}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2506.12454}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="arnaboldi2025sequence" class="col-sm-8"> <div class="title">Asymptotics of SGD in Sequence-Single Index Models and Single-Layer Attention Networks</div> <div class="author"> Luca Arnaboldi ,  Bruno Loureiro ,  Ludovic Stephan , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Florent Krzakala, Lenka Zdeborová' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">arnaboldi2025sequence</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Asymptotics of SGD in Sequence-Single Index Models and Single-Layer Attention Networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Arnaboldi, Luca and Loureiro, Bruno and Stephan, Ludovic and Krzakala, Florent and Zdeborová, Lenka}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2506.02651}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{stat.ML}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="fan2025replica" class="col-sm-8"> <div class="title">Dynamical mean-field analysis of adaptive Langevin diffusions: Replica-symmetric fixed point and empirical Bayes</div> <div class="author"> Zhou Fan ,  Justin Ko ,  Bruno Loureiro , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Yue M. Lu, Yandi Shen' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">fan2025replica</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Dynamical mean-field analysis of adaptive Langevin diffusions: Replica-symmetric fixed point and empirical Bayes}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fan, Zhou and Ko, Justin and Loureiro, Bruno and Lu, Yue M. and Shen, Yandi}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2504.15558}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{math.ST}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="fan2025propagation" class="col-sm-8"> <div class="title">Dynamical mean-field analysis of adaptive Langevin diffusions: Propagation-of-chaos and convergence of the linear response</div> <div class="author"> Zhou Fan ,  Justin Ko ,  Bruno Loureiro , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Yue M. Lu, Yandi Shen' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">fan2025propagation</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Dynamical mean-field analysis of adaptive Langevin diffusions: Propagation-of-chaos and convergence of the linear response}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fan, Zhou and Ko, Justin and Loureiro, Bruno and Lu, Yue M. and Shen, Yandi}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2504.15556}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{math.ST}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="defilippis2025optimal" class="col-sm-8"> <div class="title">Optimal Spectral Transitions in High-Dimensional Multi-Index Models</div> <div class="author"> Leonardo Defilippis ,  Yatin Dandi ,  Pierre Mergny , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Florent Krzakala, Bruno Loureiro' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">defilippis2025optimal</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Optimal Spectral Transitions in High-Dimensional Multi-Index Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Defilippis, Leonardo and Dandi, Yatin and Mergny, Pierre and Krzakala, Florent and Loureiro, Bruno}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2502.02545}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.LG}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">AISTATS</abbr> </div> <div id="dandi2024random" class="col-sm-8"> <div class="title">A Random Matrix Theory Perspective on the Spectrum of Learned Features and Asymptotic Generalization Capabilities</div> <div class="author"> Yatin Dandi ,  Luca Pesce ,  Hugo Cui , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Florent Krzakala, Yue Lu, Bruno Loureiro' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of The 28th International Conference on Artificial Intelligence and Statistics</em> , 03–05 may 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://raw.githubusercontent.com/mlresearch/v258/main/assets/dandi25a/dandi25a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>A key property of neural networks is their capacity of adapting to data during training. Yet, our current mathematical understanding of feature learning and its relationship to generalization remain limited. In this work, we provide a random matrix analysis of how fully-connected two-layer neural networks adapt to the target function after a single, but aggressive, gradient descent step. We rigorously establish the equivalence between the updated features and an isotropic spiked random feature model, in the limit of large batch size. For the latter model, we derive a deterministic equivalent description of the feature empirical covariance matrix in terms of certain low-dimensional operators. This allows us to sharply characterize the impact of training in the asymptotic feature spectrum, and in particular, provides a theoretical grounding for how the tails of the feature spectrum modify with training. The deterministic equivalent further yields the exact asymptotic generalization error, shedding light on the mechanisms behind its improvement in the presence of feature learning. Our result goes beyond standard random matrix ensembles, and therefore we believe it is of independent technical interest. Different from previous work, our result holds in the challenging maximal learning rate regime, is fully rigorous and allows for finitely supported second layer initialization, which turns out to be crucial for studying the functional expressivity of the learned features. This provides a sharp description of the impact of feature learning in the generalization of two-layer neural networks, beyond the random features and lazy training regimes.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">dandi2024random</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Random Matrix Theory Perspective on the Spectrum of Learned Features and Asymptotic Generalization Capabilities}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dandi, Yatin and Pesce, Luca and Cui, Hugo and Krzakala, Florent and Lu, Yue and Loureiro, Bruno}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of The 28th International Conference on Artificial Intelligence and Statistics}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2224--2232}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Li, Yingzhen and Mandt, Stephan and Agrawal, Shipra and Khan, Emtiyaz}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{258}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{03--05 May}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://proceedings.mlr.press/v258/dandi25a.html}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">MLST</abbr> </div> <div id="soletskyi2024theoretical" class="col-sm-8"> <div class="title">A Theoretical Perspective on Mode Collapse in Variational Inference</div> <div class="author"> Roman Soletskyi ,  Marylou Gabrié ,  and  Bruno Loureiro </div> <div class="periodical"> <em>Machine Learning: Science and Technology</em>, 03–05 may 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>While deep learning has expanded the possibilities for highly expressive variational families, the practical benefits of these tools for variational inference (VI) are often limited by the minimization of the traditional Kullback-Leibler objective, which can yield suboptimal solutions. A major challenge in this context is \emphmode collapse: the phenomenon where a model concentrates on a few modes of the target distribution during training, despite being statistically capable of expressing them all. In this work, we carry a theoretical investigation of mode collapse for the gradient flow on Gaussian mixture models. We identify the key low-dimensional statistics characterizing the flow, and derive a closed set of low-dimensional equations governing their evolution. Leveraging this compact description, we show that mode collapse is present even in statistically favorable scenarios, and identify two key mechanisms driving it: mean alignment and vanishing weight. Our theoretical findings are consistent with the implementation of VI using normalizing flows, a class of popular generative models, thereby offering practical insights.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">soletskyi2024theoretical</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Soletskyi, Roman and Gabrié, Marylou and Loureiro, Bruno}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Theoretical Perspective on Mode Collapse in Variational Inference}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Machine Learning: Science and Technology}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://iopscience.iop.org/article/10.1088/2632-2153/adde2a}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">AISTATS</abbr> </div> <div id="troiani2024fundamental" class="col-sm-8"> <div class="title">Fundamental computational limits of weak learnability in high-dimensional multi-index models</div> <div class="author"> Emanuele Troiani ,  Yatin Dandi ,  Leonardo Defilippis , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Lenka Zdeborova, Bruno Loureiro, Florent Krzakala' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of The 28th International Conference on Artificial Intelligence and Statistics</em> , 03–05 may 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://raw.githubusercontent.com/mlresearch/v258/main/assets/troiani25a/troiani25a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Multi-index models - functions which only depend on the covariates through a non-linear transformation of their projection on a subspace - are a useful benchmark for investigating feature learning with neural networks. This paper examines the theoretical boundaries of efficient learnability in this hypothesis class, focusing particularly on the minimum sample complexity required for weakly recovering their low-dimensional structure with first-order iterative algorithms, in the high-dimensional regime where the number of samples is n=αd is proportional to the covariate dimension d. Our findings unfold in three parts: (i) first, we identify under which conditions a \textittrivial subspace can be learned with a single step of a first-order algorithm for any α&gt;0; (ii) second, in the case where the trivial subspace is empty, we provide necessary and sufficient conditions for the existence of an \it easy subspace consisting of directions that can be learned only above a certain sample complexity α&gt;\alpha_c. The critical threshold \alpha_c marks the presence of a computational phase transition, in the sense that it is conjectured that no efficient iterative algorithm can succeed for α&lt;\alpha_c. In a limited but interesting set of really hard directions -akin to the parity problem- \alpha_c is found to diverge. Finally, (iii) we demonstrate that interactions between different directions can result in an intricate hierarchical learning phenomenon, where some directions can be learned sequentially when coupled to easier ones. Our analytical approach is built on the optimality of approximate message-passing algorithms among first-order iterative methods, delineating the fundamental learnability limit across a broad spectrum of algorithms, including neural networks trained with gradient descent.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">troiani2024fundamental</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fundamental computational limits of weak learnability in high-dimensional multi-index models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Troiani, Emanuele and Dandi, Yatin and Defilippis, Leonardo and Zdeborova, Lenka and Loureiro, Bruno and Krzakala, Florent}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of The 28th International Conference on Artificial Intelligence and Statistics}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2467--2475}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Li, Yingzhen and Mandt, Stephan and Agrawal, Shipra and Khan, Emtiyaz}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{258}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{03--05 May}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://proceedings.mlr.press/v258/troiani25a.html}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">AISTATS</abbr> </div> <div id="tanner2024high" class="col-sm-8"> <div class="title">A High Dimensional Statistical Model for Adversarial Training: Geometry and Trade-Offs</div> <div class="author"> Kasimir Tanner ,  Matteo Vilucchio ,  Bruno Loureiro , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Florent Krzakala' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of The 28th International Conference on Artificial Intelligence and Statistics</em> , 03–05 may 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://raw.githubusercontent.com/mlresearch/v258/main/assets/tanner25a/tanner25a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>This work investigates adversarial training in the context of margin-based linear classifiers in the high-dimensional regime where the dimension d and the number of data points n diverge with a fixed ratio α= n / d. We introduce a tractable mathematical model where the interplay between the data and adversarial attacker geometries can be studied, while capturing the core phenomenology observed in the adversarial robustness literature. Our main theoretical contribution is an exact asymptotic description of the sufficient statistics for the adversarial empirical risk minimiser, under generic convex and non-increasing losses for a Block Feature Model. Our result allow us to precisely characterise which directions in the data are associated with a higher generalisation/robustness trade-off, as defined by a robustness and a usefulness metric. This goes beyond previous models in the literature, which fail to capture a difference in performance between adversarially trained models in the high sample complexity regime. In particular, we unveil the existence of directions which can be defended without penalising accuracy. Finally, we show the advantage of defending non-robust features during training, identifying a uniform protection as an inherently effective defence mechanism.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">tanner2024high</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A High Dimensional Statistical Model for Adversarial Training: Geometry and Trade-Offs}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tanner, Kasimir and Vilucchio, Matteo and Loureiro, Bruno and Krzakala, Florent}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of The 28th International Conference on Artificial Intelligence and Statistics}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2530--2538}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Li, Yingzhen and Mandt, Stephan and Agrawal, Shipra and Khan, Emtiyaz}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{258}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{03--05 May}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://proceedings.mlr.press/v258/tanner25a.html}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="vilucchio2024geometry" class="col-sm-8"> <div class="title">On the Geometry of Regularization in Adversarial Training: High-Dimensional Asymptotics and Generalization Bounds</div> <div class="author"> Matteo Vilucchio ,  Nikolaos Tsilivis ,  Bruno Loureiro , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Julia Kempe' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> 03–05 may 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">vilucchio2024geometry</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On the Geometry of Regularization in Adversarial Training: High-Dimensional Asymptotics and Generalization Bounds}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Vilucchio, Matteo and Tsilivis, Nikolaos and Loureiro, Bruno and Kempe, Julia}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2410.16073}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{stat.ML}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICML</abbr> </div> <div id="arnaboldi2024online" class="col-sm-8"> <div class="title">Online Learning and Information Exponents: The Importance of Batch size &amp; Time/Complexity Tradeoffs</div> <div class="author"> Luca Arnaboldi ,  Yatin Dandi ,  Florent Krzakala , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Bruno Loureiro, Luca Pesce, Ludovic Stephan' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 41st International Conference on Machine Learning</em> , 21–27 jul 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://raw.githubusercontent.com/mlresearch/v235/main/assets/arnaboldi24a/arnaboldi24a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>We study the impact of the batch size n_b on the iteration time T of training two-layer neural networks with one-pass stochastic gradient descent (SGD) on multi-index target functions of isotropic covariates. We characterize the optimal batch size minimizing the iteration time as a function of the hardness of the target, as characterized by the information exponents. We show that performing gradient updates with large batches n_b ≲d^\frac\ell2 minimizes the training time without changing the total sample complexity, where \ell is the information exponent of the target to be learned and d is the input dimension. However, larger batch sizes than n_b ≫d^\frac\ell2 are detrimental for improving the time complexity of SGD. We provably overcome this fundamental limitation via a different training protocol, <em>Correlation loss SGD</em>, which suppresses the auto-correlation terms in the loss function. We show that one can track the training progress by a system of low-dimensional ordinary differential equations (ODEs). Finally, we validate our theoretical results with numerical experiments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">arnaboldi2024online</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Online Learning and Information Exponents: The Importance of Batch size &amp;amp; {T}ime/{C}omplexity Tradeoffs}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Arnaboldi, Luca and Dandi, Yatin and Krzakala, Florent and Loureiro, Bruno and Pesce, Luca and Stephan, Ludovic}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 41st International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1730--1762}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{235}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{21--27 Jul}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://proceedings.mlr.press/v235/arnaboldi24a.html}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">NeurIPS</abbr> </div> <div id="defilippis2024dimensionfree" class="col-sm-8"> <div class="title">Dimension-free deterministic equivalents and scaling laws for random feature regression</div> <div class="author"> Leonardo Defilippis ,  Bruno Loureiro ,  and  Theodor Misiakiewicz </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em> , 21–27 jul 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">defilippis2024dimensionfree</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Defilippis, Leonardo and Loureiro, Bruno and Misiakiewicz, Theodor}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Globerson, A. and Mackey, L. and Belgrave, D. and Fan, A. and Paquet, U. and Tomczak, J. and Zhang, C.}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{104630--104693}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Curran Associates, Inc.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Dimension-free deterministic equivalents and scaling laws for random feature regression}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://proceedings.neurips.cc/paper_files/paper/2024/file/bd18189308a4c45c7d71ca83acf3deaa-Paper-Conference.pdf}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{37}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">UAI</abbr> </div> <div id="clarté2024analysis" class="col-sm-8"> <div class="title">Analysis of Bootstrap and Subsampling in High-dimensional Regularized Regression</div> <div class="author"> Lucas Clarté ,  Adrien Vandenbroucque ,  Guillaume Dalle , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Bruno Loureiro, Florent Krzakala, Lenka Zdeborová' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the Fortieth Conference on Uncertainty in Artificial Intelligence</em> , 15–19 jul 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://raw.githubusercontent.com/mlresearch/v244/main/assets/clarte24a/clarte24a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>We investigate popular resampling methods for estimating the uncertainty of statistical models, such as subsampling, bootstrap and the jackknife, and their performance in high-dimensional supervised regression tasks. We provide a tight asymptotic description of the biases and variances estimated by these methods in the context of generalized linear models, such as ridge and logistic regression, taking the limit where the number of samples n and dimension d of the covariates grow at a comparable rate: α=n/d fixed. Our findings are three-fold: i) resampling methods are fraught with problems in high dimensions and exhibit the double-descent-like behavior typical of these situations; ii) only when αis large enough do they provide consistent and reliable error estimations (we give convergence rates); iii) in the over-parametrized regime α&lt;1 relevant to modern machine learning practice, their predictions are not consistent, even with optimal regularization.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">clarté2024analysis</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Analysis of Bootstrap and Subsampling in High-dimensional Regularized Regression}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Clart\'e, Lucas and Vandenbroucque, Adrien and Dalle, Guillaume and Loureiro, Bruno and Krzakala, Florent and Zdeborov\'a, Lenka}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Fortieth Conference on Uncertainty in Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{787--819}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Kiyavash, Negar and Mooij, Joris M.}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{244}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{15--19 Jul}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://proceedings.mlr.press/v244/clarte24a.html}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICML</abbr> </div> <div id="schroder2024asymptotics" class="col-sm-8"> <div class="title">Asymptotics of Learning with Deep Structured (Random) Features</div> <div class="author"> Dominik Schröder ,  Daniil Dmitriev ,  Hugo Cui , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Bruno Loureiro' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 41st International Conference on Machine Learning</em> , 21–27 jul 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://raw.githubusercontent.com/mlresearch/v235/main/assets/schroder24a/schroder24a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>For a large class of feature maps we provide a tight asymptotic characterisation of the test error associated with learning the readout layer, in the high-dimensional limit where the input dimension, hidden layer widths, and number of training samples are proportionally large. This characterization is formulated in terms of the population covariance of the features. Our work is partially motivated by the problem of learning with Gaussian rainbow neural networks, namely deep non-linear fully-connected networks with random but structured weights, whose row-wise covariances are further allowed to depend on the weights of previous layers. For such networks we also derive a closed-form formula for the feature covariance in terms of the weight matrices. We further find that in some cases our results can capture feature maps learned by deep, finite-width neural networks trained under gradient descent.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">schroder2024asymptotics</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Asymptotics of Learning with Deep Structured ({R}andom) Features}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Schr\"{o}der, Dominik and Dmitriev, Daniil and Cui, Hugo and Loureiro, Bruno}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 41st International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{43862--43894}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{235}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{21--27 Jul}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://proceedings.mlr.press/v235/schroder24a.html}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICML</abbr> </div> <div id="cui2024asymptotics" class="col-sm-8"> <div class="title">Asymptotics of feature learning in two-layer networks after one gradient-step</div> <div class="author"> Hugo Cui ,  Luca Pesce ,  Yatin Dandi , and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Florent Krzakala, Yue Lu, Lenka Zdeborova, Bruno Loureiro' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 41st International Conference on Machine Learning</em> , 21–27 jul 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://raw.githubusercontent.com/mlresearch/v235/main/assets/cui24d/cui24d.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>In this manuscript, we investigate the problem of how two-layer neural networks learn features from data, and improve over the kernel regime, after being trained with a single gradient descent step. Leveraging the insight from (Ba et al., 2022), we model the trained network by a spiked Random Features (sRF) model. Further building on recent progress on Gaussian universality (Dandi et al., 2023), we provide an exact asymptotic description of the generalization error of the sRF in the high-dimensional limit where the number of samples, the width, and the input dimension grow at a proportional rate. The resulting characterization for sRFs also captures closely the learning curves of the original network model. This enables us to understand how adapting to the data is crucial for the network to efficiently learn non-linear functions in the direction of the gradient - where at initialization it can only express linear functions in this regime.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">cui2024asymptotics</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Asymptotics of feature learning in two-layer networks after one gradient-step}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cui, Hugo and Pesce, Luca and Dandi, Yatin and Krzakala, Florent and Lu, Yue and Zdeborova, Lenka and Loureiro, Bruno}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 41st International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{9662--9695}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{235}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{21--27 Jul}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://proceedings.mlr.press/v235/cui24d.html}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="adomaityte2024" class="col-sm-8"> <div class="title">High-dimensional robust regression under heavy-tailed data: asymptotics and universality</div> <div class="author"> Urte Adomaityte ,  Leonardo Defilippis ,  Bruno Loureiro , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Gabriele Sicuro' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Journal of Statistical Mechanics: Theory and Experiment</em>, Nov 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>We investigate the high-dimensional properties of robust regression estimators in the presence of heavy-tailed contamination of both the covariates and response functions. In particular, we provide a sharp asymptotic characterisation of M-estimators trained on a family of elliptical covariate and noise data distributions including cases where second and higher moments do not exist. We show that, despite being consistent, the Huber loss with optimally tuned location parameter δ is suboptimal in the high-dimensional regime in the presence of heavy-tailed noise, highlighting the necessity of further regularisation to achieve optimal performance. This result also uncovers the existence of a transition in δ as a function of the sample complexity and contamination. Moreover, we derive the decay rates for the excess risk of ridge regression. We show that, while it is both optimal and universal for covariate distributions with finite second moment, its decay rate can be considerably faster when the covariates’ second moment does not exist. Finally, we show that our formulas readily generalise to a richer family of models and data distributions, such as generalised linear estimation with arbitrary convex regularisation trained on mixture models.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">adomaityte2024</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1088/1742-5468/ad65e6}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://dx.doi.org/10.1088/1742-5468/ad65e6}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IOP Publishing}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{114002}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Adomaityte, Urte and Defilippis, Leonardo and Loureiro, Bruno and Sicuro, Gabriele}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{High-dimensional robust regression under heavy-tailed data: asymptotics and universality}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Statistical Mechanics: Theory and Experiment}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">JMLR</abbr> </div> <div id="dandi2023learning" class="col-sm-8"> <div class="title">How Two-Layer Neural Networks Learn, One (Giant) Step at a Time</div> <div class="author"> Yatin Dandi ,  Florent Krzakala ,  Bruno Loureiro , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Luca Pesce, Ludovic Stephan' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Journal of Machine Learning Research</em>, Nov 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">dandi2023learning</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dandi, Yatin and Krzakala, Florent and Loureiro, Bruno and Pesce, Luca and Stephan, Ludovic}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{How Two-Layer Neural Networks Learn, One (Giant) Step at a Time}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{25}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{349}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--65}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://jmlr.org/papers/v25/23-1543.html}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">PRE</abbr> </div> <div id="gerace2022gaussian" class="col-sm-8"> <div class="title">Gaussian universality of perceptrons with random labels</div> <div class="author"> Federica Gerace ,  Florent Krzakala ,  Bruno Loureiro , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Ludovic Stephan, Lenka Zdeborová' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Phys. Rev. E</em>, Mar 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2205.13303" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">gerace2022gaussian</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Gaussian universality of perceptrons with random labels}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gerace, Federica and Krzakala, Florent and Loureiro, Bruno and Stephan, Ludovic and Zdeborov\'a, Lenka}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Phys. Rev. E}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{109}</span><span class="p">,</span>
  <span class="na">issue</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{034305}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{18}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{American Physical Society}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1103/PhysRevE.109.034305}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.aps.org/doi/10.1103/PhysRevE.109.034305}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="arnaboldi2023escaping" class="col-sm-8"> <div class="title">Escaping mediocrity: how two-layer networks learn hard single-index models with SGD</div> <div class="author"> Luca Arnaboldi ,  Florent Krzakala ,  Bruno Loureiro , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Ludovic Stephan' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em></em> Mar 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2305.18502" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">UAI</abbr> </div> <div id="clarte2023ec" class="col-sm-8"> <div class="title">Expectation consistency for calibration of neural networks</div> <div class="author"> Lucas Clarté ,  Bruno Loureiro ,  Florent Krzakala , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Lenka Zdeborová' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence</em> , 31 jul–04 aug 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2303.02644" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v216/clarte23a.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://proceedings.mlr.press/v216/clarte23a/clarte23a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Despite their incredible performance, it is well reported that deep neural networks tend to be overoptimistic about their prediction confidence. Finding effective and efficient calibration methods for neural networks is therefore an important endeavour towards better uncertainty quantification in deep learning. In this manuscript, we introduce a novel calibration technique named expectation consistency (EC), consisting of a post-training rescaling of the last layer weights by enforcing that the average validation confidence coincides with the average proportion of correct labels. First, we show that the EC method achieves similar calibration performance to temperature scaling (TS) across different neural network architectures and data sets, all while requiring similar validation samples and computational resources. However, we argue that EC provides a principled method grounded on a Bayesian optimality principle known as the Nishimori identity. Next, we provide an asymptotic characterization of both TS and EC in a synthetic setting and show that their performance crucially depends on the target function. In particular, we discuss examples where EC significantly outperforms TS.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">clarte2023ec</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Expectation consistency for calibration of neural networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Clart\'e, Lucas and Loureiro, Bruno and Krzakala, Florent and Zdeborov\'a, Lenka}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{443--453}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Evans, Robin J. and Shpitser, Ilya}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{216}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{31 Jul--04 Aug}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">COLT</abbr> </div> <div id="arnaboldi2023high" class="col-sm-8"> <div class="title">From high-dimensional &amp; mean-field dynamics to dimensionless ODEs: A unifying approach to SGD in two-layers networks</div> <div class="author"> Luca Arnaboldi ,  Ludovic Stephan ,  Florent Krzakala , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Bruno Loureiro' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of Thirty Sixth Conference on Learning Theory</em> , 12–15 jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2302.05882" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v195/arnaboldi23a.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://proceedings.mlr.press/v195/arnaboldi23a/arnaboldi23a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>This manuscript investigates the one-pass stochastic gradient descent (SGD) dynamics of a two-layer neural network trained on Gaussian data and labels generated by a similar, though not necessarily identical, target function. We rigorously analyse the limiting dynamics via a deterministic and low-dimensional description in terms of the sufficient statistics for the population risk. Our unifying analysis bridges different regimes of interest, such as the classical gradient-flow regime of vanishing learning rate, the high-dimensional regime of large input dimension, and the overparameterised “mean-field” regime of large network width, covering as well the intermediate regimes where the limiting dynamics is determined by the interplay between these behaviours. In particular, in the high-dimensional limit, the infinite-width dynamics is found to remain close to a low-dimensional subspace spanned by the target principal directions. Our results therefore provide a unifying picture of the limiting SGD dynamics with synthetic data. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">arnaboldi2023high</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{From high-dimensional &amp;amp; mean-field dynamics to dimensionless ODEs: A unifying approach to SGD in two-layers networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Arnaboldi, Luca and Stephan, Ludovic and Krzakala, Florent and Loureiro, Bruno}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of Thirty Sixth Conference on Learning Theory}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1199--1227}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Neu, Gergely and Rosasco, Lorenzo}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{195}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{12--15 Jul}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">NeurIPS</abbr> </div> <div id="Dandi2023" class="col-sm-8"> <div class="title">Universality laws for Gaussian mixtures in generalized linear models</div> <div class="author"> Yatin Dandi ,  Ludovic Stephan ,  Florent Krzakala , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Bruno Loureiro, Lenka Zdeborová' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em> , 12–15 jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Dandi2023</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dandi, Yatin and Stephan, Ludovic and Krzakala, Florent and Loureiro, Bruno and Zdeborov\'{a}, Lenka}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Oh, A. and Neumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{54754--54768}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Curran Associates, Inc.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Universality laws for Gaussian mixtures in generalized linear models}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://proceedings.neurips.cc/paper_files/paper/2023/file/abccb8a90b30d45b948360ba41f5a20f-Paper-Conference.pdf}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{36}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICML</abbr> </div> <div id="pesce2023gaussian" class="col-sm-8"> <div class="title">Are Gaussian Data All You Need? The Extents and Limits of Universality in High-Dimensional Generalized Linear Estimation</div> <div class="author"> Luca Pesce ,  Florent Krzakala ,  Bruno Loureiro , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Ludovic Stephan' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 40th International Conference on Machine Learning</em> , 23–29 jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2302.08923" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v202/pesce23a.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://proceedings.mlr.press/v202/pesce23a/pesce23a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>In this manuscript we consider the problem of generalized linear estimation on Gaussian mixture data with labels given by a single-index model. Our first result is a sharp asymptotic expression for the test and training errors in the high-dimensional regime. Motivated by the recent stream of results on the Gaussian universality of the test and training errors in generalized linear estimation, we ask ourselves the question: "when is a single Gaussian enough to characterize the error?". Our formula allows us to give sharp answers to this question, both in the positive and negative directions. More precisely, we show that the sufficient conditions for Gaussian universality (or lack thereof) crucially depend on the alignment between the target weights and the means and covariances of the mixture clusters, which we precisely quantify. In the particular case of least-squares interpolation, we prove a strong universality property of the training error and show it follows a simple, closed-form expression. Finally, we apply our results to real datasets, clarifying some recent discussions in the literature about Gaussian universality of the errors in this context.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">pesce2023gaussian</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Are {G}aussian Data All You Need? {T}he Extents and Limits of Universality in High-Dimensional Generalized Linear Estimation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pesce, Luca and Krzakala, Florent and Loureiro, Bruno and Stephan, Ludovic}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 40th International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{27680--27708}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{202}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{23--29 Jul}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICML</abbr> </div> <div id="schroder2023deterministic" class="col-sm-8"> <div class="title">Deterministic equivalent and error universality of deep random features learning</div> <div class="author"> Dominik Schröder ,  Hugo Cui ,  Daniil Dmitriev , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Bruno Loureiro' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 40th International Conference on Machine Learning</em> , 23–29 jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2302.00401" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v202/schroder23a/schroder23a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>This manuscript considers the problem of learning a random Gaussian network function using a fully connected network with frozen intermediate layers and trainable readout layer. This problem can be seen as a natural generalization of the widely studied random features model to deeper architectures. First, we prove Gaussian universality of the test error in a ridge regression setting where the learner and target networks share the same intermediate layers, and provide a sharp asymptotic formula for it. Establishing this result requires proving a deterministic equivalent for traces of the deep random features sample covariance matrices which can be of independent interest. Second, we conjecture the asymptotic Gaussian universality of the test error in the more general setting of arbitrary convex losses and generic learner/target architectures. We provide extensive numerical evidence for this conjecture, which requires the derivation of closed-form expressions for the layer-wise post-activation population covariances. In light of our results, we investigate the interplay between architecture design and implicit regularization.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">schroder2023deterministic</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Deterministic equivalent and error universality of deep random features learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Schr\"{o}der, Dominik and Cui, Hugo and Dmitriev, Daniil and Loureiro, Bruno}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 40th International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{30285--30320}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{202}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{23--29 Jul}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://proceedings.mlr.press/v202/schroder23a.html}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">AISTATS</abbr> </div> <div id="clarte2022overparametrized" class="col-sm-8"> <div class="title">On double-descent in uncertainty quantification in overparametrized models</div> <div class="author"> Lucas Clarte ,  Bruno Loureiro ,  Florent Krzakala , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Lenka Zdeborova' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of The 26th International Conference on Artificial Intelligence and Statistics</em> , 25–27 apr 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2210.12760" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v206/clarte23a.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://proceedings.mlr.press/v206/clarte23a/clarte23a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Uncertainty quantification is a central challenge in reliable and trustworthy machine learning. Naive measures such as last-layer scores are well-known to yield overconfident estimates in the context of overparametrized neural networks. Several methods, ranging from temperature scaling to different Bayesian treatments of neural networks, have been proposed to mitigate overconfidence, most often supported by the numerical observation that they yield better calibrated uncertainty measures. In this work, we provide a sharp comparison between popular uncertainty measures for binary classification in a mathematically tractable model for overparametrized neural networks: the random features model. We discuss a trade-off between classification accuracy and calibration, unveiling a double descent behavior in the calibration curve of optimally regularised estimators as a function of overparametrization. This is in contrast with the empirical Bayes method, which we show to be well calibrated in our setting despite the higher generalization error and overparametrization.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">clarte2022overparametrized</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On double-descent in uncertainty quantification in overparametrized models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Clarte, Lucas and Loureiro, Bruno and Krzakala, Florent and Zdeborova, Lenka}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of The 26th International Conference on Artificial Intelligence and Statistics}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{7089--7125}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{206}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{25--27 Apr}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">MLST</abbr> </div> <div id="Cornacchia_2023" class="col-sm-8"> <div class="title">Learning curves for the multi-class teacher–student perceptron</div> <div class="author"> Elisabetta Cornacchia ,  Francesca Mignacco ,  Rodrigo Veiga , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Cédric Gerbelot, Bruno Loureiro, Lenka Zdeborová' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Machine Learning: Science and Technology</em>, Feb 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2203.12094" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dx.doi.org/10.1088/2632-2153/acb428" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>One of the most classical results in high-dimensional learning theory provides a closed-form expression for the generalisation error of binary classification with a single-layer teacher–student perceptron on i.i.d. Gaussian inputs. Both Bayes-optimal (BO) estimation and empirical risk minimisation (ERM) were extensively analysed in this setting. At the same time, a considerable part of modern machine learning practice concerns multi-class classification. Yet, an analogous analysis for the multi-class teacher–student perceptron was missing. In this manuscript we fill this gap by deriving and evaluating asymptotic expressions for the BO and ERM generalisation errors in the high-dimensional regime. For Gaussian teacher, we investigate the performance of ERM with both cross-entropy and square losses, and explore the role of ridge regularisation in approaching Bayes-optimality. In particular, we observe that regularised cross-entropy minimisation yields close-to-optimal accuracy. Instead, for Rademacher teacher we show that a first-order phase transition arises in the BO performance.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Cornacchia_2023</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1088/2632-2153/acb428}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IOP Publishing}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{015019}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cornacchia, Elisabetta and Mignacco, Francesca and Veiga, Rodrigo and Gerbelot, Cédric and Loureiro, Bruno and Zdeborová, Lenka}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning curves for the multi-class teacher–student perceptron}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Machine Learning: Science and Technology}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">MLST</abbr> </div> <div id="Clarté_2023" class="col-sm-8"> <div class="title">Theoretical characterization of uncertainty in high-dimensional linear classification</div> <div class="author"> Lucas Clarté ,  Bruno Loureiro ,  Florent Krzakala , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Lenka Zdeborová' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Machine Learning: Science and Technology</em>, Jun 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2202.03295" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dx.doi.org/10.1088/2632-2153/acd749" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Being able to reliably assess not only the accuracy but also the uncertainty of models’ predictions is an important endeavor in modern machine learning. Even if the model generating the data and labels is known, computing the intrinsic uncertainty after learning the model from a limited number of samples amounts to sampling the corresponding posterior probability measure. Such sampling is computationally challenging in high-dimensional problems and theoretical results on heuristic uncertainty estimators in high-dimensions are thus scarce. In this manuscript, we characterize uncertainty for learning from a limited number of samples of high-dimensional Gaussian input data and labels generated by the probit model. In this setting, the Bayesian uncertainty (i.e. the posterior marginals) can be asymptotically obtained by the approximate message passing algorithm, bypassing the canonical but costly Monte Carlo sampling of the posterior. We then provide a closed-form formula for the joint statistics between the logistic classifier, the uncertainty of the statistically optimal Bayesian classifier and the ground-truth probit uncertainty. The formula allows us to investigate the calibration of the logistic classifier learning from a limited amount of samples. We discuss how over-confidence can be mitigated by appropriately regularizing.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Clarté_2023</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1088/2632-2153/acd749}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IOP Publishing}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{025029}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Clarté, Lucas and Loureiro, Bruno and Krzakala, Florent and Zdeborová, Lenka}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Theoretical characterization of uncertainty in high-dimensional linear classification}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Machine Learning: Science and Technology}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">MLST</abbr> </div> <div id="cui2022error" class="col-sm-8"> <div class="title">Error scaling laws for kernel classification under source and capacity conditions</div> <div class="author"> Hugo Cui ,  Bruno Loureiro ,  Florent Krzakala , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Lenka Zdeborová' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Machine Learning: Science and Technology</em>, Aug 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2201.12655" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dx.doi.org/10.1088/2632-2153/acf041" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>In this manuscript we consider the problem of kernel classification. While worst-case bounds on the decay rate of the prediction error with the number of samples are known for some classifiers, they often fail to accurately describe the learning curves of real data sets. In this work, we consider the important class of data sets satisfying the standard source and capacity conditions, comprising a number of real data sets as we show numerically. Under the Gaussian design, we derive the decay rates for the misclassification (prediction) error as a function of the source and capacity coefficients. We do so for two standard kernel classification settings, namely margin-maximizing support vector machines and ridge classification, and contrast the two methods. We find that our rates tightly describe the learning curves for this class of data sets, and are also observed on real data. Our results can also be seen as an explicit prediction of the exponents of a scaling law for kernel classification that is accurate on some real datasets.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">cui2022error</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1088/2632-2153/acf041}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IOP Publishing}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{035033}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cui, Hugo and Loureiro, Bruno and Krzakala, Florent and Zdeborová, Lenka}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Error scaling laws for kernel classification under source and capacity conditions}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Machine Learning: Science and Technology}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">IEEE TIT</abbr> </div> <div id="bereyhi2022bayesian" class="col-sm-8"> <div class="title">Bayesian Inference With Nonlinear Generative Models: Comments on Secure Learning</div> <div class="author"> Ali Bereyhi ,  Bruno Loureiro ,  Florent Krzakala , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Ralf R. Müller, Hermann Schulz-Baldes' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>IEEE Transactions on Information Theory</em>, Dec 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2201.09986" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10286532" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Unlike the classical linear model, nonlinear generative models have been addressed sparsely in the literature of statistical learning. This work aims to shed light on these models and their secrecy potential. To this end, we invoke the replica method to derive the asymptotic normalized cross entropy in an inverse probability problem whose generative model is described by a Gaussian random field with a generic covariance function. Our derivations further demonstrate the asymptotic statistical decoupling of the Bayesian estimator and specify the decoupled setting for a given nonlinear model. The replica solution depicts that strictly nonlinear models establish an all-or-nothing phase transition: there exists a critical load at which the optimal Bayesian inference changes from perfect to an uncorrelated learning. Based on this finding, we design a new secure coding scheme which achieves the secrecy capacity of the wiretap channel. This interesting result implies that strictly nonlinear generative models are perfectly secured without any secure coding. We justify this latter statement through the analysis of an illustrative model for perfectly secure and reliable inference.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">bereyhi2022bayesian</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bereyhi, Ali and Loureiro, Bruno and Krzakala, Florent and Müller, Ralf R. and Schulz-Baldes, Hermann}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Information Theory}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Bayesian Inference With Nonlinear Generative Models: Comments on Secure Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{69}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{7998-8028}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TIT.2023.3325187}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1557-9654}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">NeurIPS</abbr> </div> <div id="pesce2022subspace" class="col-sm-8"> <div class="title">Subspace clustering in high-dimensions: Phase transitions &amp; Statistical-to-Computational gap</div> <div class="author"> Luca Pesce ,  Bruno Loureiro ,  Florent Krzakala , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Lenka Zdeborová' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em> , Dec 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2205.13527" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/ad3d0ac42b4b5cc3b5f0ca10107d5c84-Abstract-Conference.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/ad3d0ac42b4b5cc3b5f0ca10107d5c84-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">pesce2022subspace</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pesce, Luca and Loureiro, Bruno and Krzakala, Florent and Zdeborov\'{a}, Lenka}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Koyejo, S. and Mohamed, S. and Agarwal, A. and Belgrave, D. and Cho, K. and Oh, A.}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{27087--27099}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Curran Associates, Inc.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Subspace clustering in high-dimensions: Phase transitions \&amp;amp; Statistical-to-Computational gap}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{35}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">NeurIPS</abbr> </div> <div id="veiga2022phase" class="col-sm-8"> <div class="title">Phase diagram of Stochastic Gradient Descent in high-dimensional two-layer neural networks</div> <div class="author"> Rodrigo Veiga ,  Ludovic Stephan ,  Bruno Loureiro , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Florent Krzakala, Lenka Zdeborová' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em> , Dec 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2202.00293" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/939bb847ebfd14c6e4d3b5705e562054-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">veiga2022phase</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Veiga, Rodrigo and Stephan, Ludovic and Loureiro, Bruno and Krzakala, Florent and Zdeborov\'{a}, Lenka}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Koyejo, S. and Mohamed, S. and Agarwal, A. and Belgrave, D. and Cho, K. and Oh, A.}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{23244--23255}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Curran Associates, Inc.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Phase diagram of Stochastic Gradient Descent in high-dimensional two-layer neural networks}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{35}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICML</abbr> </div> <div id="pmlr-v162-loureiro22a" class="col-sm-8"> <div class="title">Fluctuations, Bias, Variance &amp; Ensemble of Learners: Exact Asymptotics for Convex Losses in High-Dimension</div> <div class="author"> Bruno Loureiro ,  Cedric Gerbelot ,  Maria Refinetti , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Gabriele Sicuro, Florent Krzakala' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 39th International Conference on Machine Learning</em> , 17–23 jul 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2201.13383" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v162/loureiro22a/loureiro22a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>From the sampling of data to the initialisation of parameters, randomness is ubiquitous in modern Machine Learning practice. Understanding the statistical fluctuations engendered by the different sources of randomness in prediction is therefore key to understanding robust generalisation. In this manuscript we develop a quantitative and rigorous theory for the study of fluctuations in an ensemble of generalised linear models trained on different, but correlated, features in high-dimensions. In particular, we provide a complete description of the asymptotic joint distribution of the empirical risk minimiser for generic convex loss and regularisation in the high-dimensional limit. Our result encompasses a rich set of classification and regression tasks, such as the lazy regime of overparametrised neural networks, or equivalently the random features approximation of kernels. While allowing to study directly the mitigating effect of ensembling (or bagging) on the bias-variance decomposition of the test error, our analysis also helps disentangle the contribution of statistical fluctuations, and the singular role played by the interpolation threshold that are at the roots of the “double-descent” phenomenon.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">pmlr-v162-loureiro22a</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fluctuations, Bias, Variance &amp;amp; Ensemble of Learners: Exact Asymptotics for Convex Losses in High-Dimension}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Loureiro, Bruno and Gerbelot, Cedric and Refinetti, Maria and Sicuro, Gabriele and Krzakala, Florent}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 39th International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{14283--14314}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{162}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{17--23 Jul}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://proceedings.mlr.press/v162/loureiro22a.html}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">MSML</abbr> </div> <div id="goldt2020phase" class="col-sm-8"> <div class="title">The Gaussian equivalence of generative models for learning with shallow neural networks</div> <div class="author"> Sebastian Goldt ,  Bruno Loureiro ,  Galen Reeves , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Florent Krzakala, Marc Mezard, Lenka Zdeborova' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 2nd Mathematical and Scientific Machine Learning Conference</em> , 16–19 aug 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2006.14709" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v145/goldt22a.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://proceedings.mlr.press/v145/goldt22a/goldt22a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Understanding the impact of data structure on the computational tractability of learning is a key challenge for the theory of neural networks. Many theoretical works do not explicitly model training data, or assume that inputs are drawn component-wise independently from some simple probability distribution. Here, we go beyond this simple paradigm by studying the performance of neural networks trained on data drawn from pre-trained generative models. This is possible due to a Gaussian equivalence stating that the key metrics of interest, such as the training and test errors, can be fully captured by an appropriately chosen Gaussian model. We provide three strands of rigorous, analytical and numerical evidence corroborating this equivalence. First, we establish rigorous conditions for the Gaussian equivalence to hold in the case of single-layer generative models, as well as deterministic rates for convergence in distribution. Second, we leverage this equivalence to derive a closed set of equations describing the generalisation performance of two widely studied machine learning problems: two-layer neural networks trained using one-pass stochastic gradient descent, and full-batch pre-learned features or kernel methods. Finally, we perform experiments demonstrating how our theory applies to deep, pre-trained generative models. These results open a viable path to the theoretical study of machine learning models with realistic data. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">goldt2020phase</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Gaussian equivalence of generative models for learning with shallow neural networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Goldt, Sebastian and Loureiro, Bruno and Reeves, Galen and Krzakala, Florent and Mezard, Marc and Zdeborova, Lenka}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2nd Mathematical and Scientific Machine Learning Conference}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{426--471}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Bruna, Joan and Hesthaven, Jan and Zdeborova, Lenka}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{145}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{16--19 Aug}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">NeurIPS</abbr> </div> <div id="loureiro2021learning" class="col-sm-8"> <div class="title">Learning Gaussian Mixtures with Generalized Linear Models: Precise Asymptotics in High-dimensions</div> <div class="author"> Bruno Loureiro ,  Gabriele Sicuro ,  Cedric Gerbelot , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Alessandro Pacco, Florent Krzakala, Lenka Zdeborová' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em> , 16–19 aug 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2106.03791" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2021/hash/543e83748234f7cbab21aa0ade66565f-Abstract.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/543e83748234f7cbab21aa0ade66565f-Paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">loureiro2021learning</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Loureiro, Bruno and Sicuro, Gabriele and Gerbelot, Cedric and Pacco, Alessandro and Krzakala, Florent and Zdeborov\'{a}, Lenka}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and Liang, P.S. and Vaughan, J. Wortman}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{10144--10157}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Curran Associates, Inc.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning Gaussian Mixtures with Generalized Linear Models: Precise Asymptotics in High-dimensions}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{34}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">NeurIPS</abbr> </div> <div id="cui2021generalization" class="col-sm-8"> <div class="title">Generalization Error Rates in Kernel Regression: The Crossover from the Noiseless to Noisy Regime</div> <div class="author"> Hugo Cui ,  Bruno Loureiro ,  Florent Krzakala , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Lenka Zdeborová' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em> , 16–19 aug 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2105.15004" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2021/hash/543bec10c8325987595fcdc492a525f4-Abstract.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/543bec10c8325987595fcdc492a525f4-Paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">cui2021generalization</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cui, Hugo and Loureiro, Bruno and Krzakala, Florent and Zdeborov\'{a}, Lenka}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and Liang, P.S. and Vaughan, J. Wortman}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{10131--10143}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Curran Associates, Inc.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Generalization Error Rates in Kernel Regression: The Crossover from the Noiseless to Noisy Regime}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{34}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">NeurIPS</abbr> </div> <div id="loureiro2021capturing" class="col-sm-8"> <div class="title">Learning curves of generic features maps for realistic datasets with a teacher-student model</div> <div class="author"> Bruno Loureiro ,  Cedric Gerbelot ,  Hugo Cui , and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Sebastian Goldt, Florent Krzakala, Marc Mezard, Lenka Zdeborová' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em> , 16–19 aug 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2102.08127" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2021/hash/9704a4fc48ae88598dcbdcdf57f3fdef-Abstract.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://proceedings.neurips.cc/paper/2021/file/9704a4fc48ae88598dcbdcdf57f3fdef-Paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">loureiro2021capturing</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Loureiro, Bruno and Gerbelot, Cedric and Cui, Hugo and Goldt, Sebastian and Krzakala, Florent and Mezard, Marc and Zdeborov\'{a}, Lenka}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and Liang, P.S. and Vaughan, J. Wortman}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{18137--18151}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Curran Associates, Inc.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning curves of generic features maps for realistic datasets with a teacher-student model}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{34}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">IEEE-TIT</abbr> </div> <div id="aubin2019spiked" class="col-sm-8"> <div class="title">The Spiked Matrix Model With Generative Priors</div> <div class="author"> Benjamin Aubin ,  Bruno Loureiro ,  Antoine Maillard , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Florent Krzakala, Lenka Zdeborová' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>IEEE Transactions on Information Theory</em>, Feb 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/1905.12385" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/9240945" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>We investigate the statistical and algorithmic properties of random neural-network generative priors in a simple inference problem: spiked-matrix estimation. We establish a rigorous expression for the performance of the Bayes-optimal estimator in the high-dimensional regime, and identify the statistical threshold for weak-recovery of the spike. Next, we derive a message-passing algorithm taking into account the latent structure of the spike, and show that its performance is asymptotically optimal for natural choices of the generative network architecture. The absence of an algorithmic gap in this case is in stark contrast to known results for sparse spikes, another popular prior for modelling low-dimensional signals, and for which no algorithm is known to achieve the optimal statistical threshold. Finally, we show that linearising our message passing algorithm yields a simple spectral method also achieving the optimal threshold for reconstruction. We conclude with an experiment on a real data set showing that our bespoke spectral method outperforms vanilla PCA.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">aubin2019spiked</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Aubin, Benjamin and Loureiro, Bruno and Maillard, Antoine and Krzakala, Florent and Zdeborová, Lenka}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Information Theory}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Spiked Matrix Model With Generative Priors}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{67}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1156-1181}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TIT.2020.3033985}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1557-9654}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">NeurIPS</abbr> </div> <div id="maillard2020phase" class="col-sm-8"> <div class="title">Phase retrieval in high dimensions: Statistical and computational phase transitions</div> <div class="author"> Antoine Maillard ,  Bruno Loureiro ,  Florent Krzakala , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Lenka Zdeborová' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em> , Feb 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2006.05228" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2020/hash/7ec0dbeee45813422897e04ad8424a5e-Abstract.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2020/file/7ec0dbeee45813422897e04ad8424a5e-Paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">maillard2020phase</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Maillard, Antoine and Loureiro, Bruno and Krzakala, Florent and Zdeborov\'{a}, Lenka}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Larochelle, H. and Ranzato, M. and Hadsell, R. and Balcan, M.F. and Lin, H.}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{11071--11082}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Curran Associates, Inc.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Phase retrieval in high dimensions: Statistical and computational phase transitions}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{33}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICML</abbr> </div> <div id="Gerace2020" class="col-sm-8"> <div class="title">Generalisation error in learning with random features and the hidden manifold model</div> <div class="author"> Federica Gerace ,  Bruno Loureiro ,  Florent Krzakala , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Marc Mezard, Lenka Zdeborova' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 37th International Conference on Machine Learning</em> , 13–18 jul 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2002.09339" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v119/gerace20a.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="http://proceedings.mlr.press/v119/gerace20a/gerace20a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>We study generalised linear regression and classification for a synthetically generated dataset encompassing different problems of interest, such as learning with random features, neural networks in the lazy training regime, and the hidden manifold model. We consider the high-dimensional regime and using the replica method from statistical physics, we provide a closed-form expression for the asymptotic generalisation performance in these problems, valid in both the under- and over-parametrised regimes and for a broad choice of generalised linear model loss functions. In particular, we show how to obtain analytically the so-called double descent behaviour for logistic regression with a peak at the interpolation threshold, we illustrate the superiority of orthogonal against random Gaussian projections in learning with random features, and discuss the role played by correlations in the data generated by the hidden manifold model. Beyond the interest in these particular problems, the theoretical formalism introduced in this manuscript provides a path to further extensions to more complex tasks.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Gerace2020</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Generalisation error in learning with random features and the hidden manifold model}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gerace, Federica and Loureiro, Bruno and Krzakala, Florent and Mezard, Marc and Zdeborova, Lenka}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 37th International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3452--3462}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{III, Hal Daumé and Singh, Aarti}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{119}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{13--18 Jul}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">MSML</abbr> </div> <div id="aubin2019phase" class="col-sm-8"> <div class="title">Exact asymptotics for phase retrieval and compressed sensing with random generative priors</div> <div class="author"> Benjamin Aubin ,  Bruno Loureiro ,  Antoine Baker , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Florent Krzakala, Lenka Zdeborová' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of The First Mathematical and Scientific Machine Learning Conference</em> , 20–24 jul 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/1912.02008" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v107/aubin20a.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="http://proceedings.mlr.press/v107/aubin20a/aubin20a.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>We consider the problem of compressed sensing and of (real-valued) phase retrieval with random measurement matrix. We derive sharp asymptotics for the information-theoretically optimal performance and for the best known polynomial algorithm for an ensemble of generative priors consisting of fully connected deep neural networks with random weight matrices and arbitrary activations. We compare the performance to sparse separable priors and conclude that in all cases analysed generative priors have a smaller statistical-to-algorithmic gap than sparse priors, giving theoretical support to previous experimental observations that generative priors might be advantageous in terms of algorithmic performance. In particular, while sparsity does not allow to perform compressive phase retrieval efficiently close to its information-theoretic limit, it is found that under the random generative prior compressed phase retrieval becomes tractable.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">aubin2019phase</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Exact asymptotics for phase retrieval and compressed sensing with random generative priors}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Aubin, Benjamin and Loureiro, Bruno and Baker, Antoine and Krzakala, Florent and Zdeborov\'a, Lenka}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of The First Mathematical and Scientific Machine Learning Conference}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{55--73}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Lu, Jianfeng and Ward, Rachel}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{107}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{20--24 Jul}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">JHEP</abbr> </div> <div id="Andrade2018" class="col-sm-8"> <div class="title">Coherence effects in disordered geometries with a field-theory dual</div> <div class="author"> Tomás Andrade ,  Antonio M. García-García ,  and  Bruno Loureiro </div> <div class="periodical"> <em>Journal of High Energy Physics</em>, Mar 2018 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/1711.10953" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1007/JHEP03(2018)187" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Andrade2018</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Andrade, Tom{\'a}s and Garc{\'i}a-Garc{\'i}a, Antonio M. and Loureiro, Bruno}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Coherence effects in disordered geometries with a field-theory dual}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of High Energy Physics}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">day</span> <span class="p">=</span> <span class="s">{29}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{187}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1029-8479}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/JHEP03(2018)187}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">PRL</abbr> </div> <div id="PhysRevLett.120.241603" class="col-sm-8"> <div class="title">Chaotic-Integrable Transition in the Sachdev-Ye-Kitaev Model</div> <div class="author"> Antonio M. Garcı́a-Garcı́a ,  Bruno Loureiro ,  Aurelio Romero-Bermúdez , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Masaki Tezuka' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Phys. Rev. Lett.</em>, Jun 2018 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/1707.02197" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.aps.org/doi/10.1103/PhysRevLett.120.241603" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">PhysRevLett.120.241603</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Chaotic-Integrable Transition in the Sachdev-Ye-Kitaev Model}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Garc\'{\i}a-Garc\'{\i}a, Antonio M. and Loureiro, Bruno and Romero-Berm\'udez, Aurelio and Tezuka, Masaki}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Phys. Rev. Lett.}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{120}</span><span class="p">,</span>
  <span class="na">issue</span> <span class="p">=</span> <span class="s">{24}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{241603}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{American Physical Society}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1103/PhysRevLett.120.241603}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">PRD</abbr> </div> <div id="PhysRevD.94.086007" class="col-sm-8"> <div class="title">Transport in a gravity dual with a varying gravitational coupling constant</div> <div class="author"> Antonio M. Garcı́a-Garcı́a ,  Bruno Loureiro ,  and  Aurelio Romero-Bermúdez </div> <div class="periodical"> <em>Phys. Rev. D</em>, Oct 2016 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/1606.01142" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.aps.org/doi/10.1103/PhysRevD.94.086007" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">PhysRevD.94.086007</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Transport in a gravity dual with a varying gravitational coupling constant}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Garc\'{\i}a-Garc\'{\i}a, Antonio M. and Loureiro, Bruno and Romero-Berm\'udez, Aurelio}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Phys. Rev. D}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{94}</span><span class="p">,</span>
  <span class="na">issue</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{086007}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{21}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{American Physical Society}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1103/PhysRevD.94.086007}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">PRD</abbr> </div> <div id="PhysRevD.93.065025" class="col-sm-8"> <div class="title">Marginal and irrelevant disorder in Einstein-Maxwell backgrounds</div> <div class="author"> Antonio M. Garcı́a-Garcı́a ,  and  Bruno Loureiro </div> <div class="periodical"> <em>Phys. Rev. D</em>, Mar 2016 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/1512.00194" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.aps.org/doi/10.1103/PhysRevD.93.065025" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">PhysRevD.93.065025</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Marginal and irrelevant disorder in Einstein-Maxwell backgrounds}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Garc\'{\i}a-Garc\'{\i}a, Antonio M. and Loureiro, Bruno}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Phys. Rev. D}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{93}</span><span class="p">,</span>
  <span class="na">issue</span> <span class="p">=</span> <span class="s">{6}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{065025}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{13}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{American Physical Society}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1103/PhysRevD.93.065025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2026 Bruno Loureiro. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-7KENCKL5VM"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-7KENCKL5VM");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>